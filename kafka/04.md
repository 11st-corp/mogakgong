# 카프카 리플리케이션

일반적인 분산시스템은 애플리케이션의 고가용성을 위해 내부적으로 리플리케이션 동작을 하는데, 이 동작의 구현은 어렵고 복잡해 성능 저하를 불러올 수 있다.

이를 보완하기 위해 카프카는 데이터의 안정성을 보장하고, 고가용성을 제공하도록 설계됐다.

---

## 4.1 카프카 리플리케이션

고가용성 분산 스트리밍 플랫폼인 카프카는 무수히 많은 데이터 파이프라인의 정중앙에 위치해 메인 허브 역할을 한다.
따라서 카프카와 연결된 전체 데이터 파이프라인에 영향을 미친다면 매우 심각한 문제가 발생하기 때문에 초기 설계단계에서부터 브로커 한 두대에서
장애가 발생하더라도 중앙 데이터 허브로서 안정적인 서비스가 운영될 수 있도록 구상되었다.

### 4.1.1 리플리케이션 동작 개요

카프카는 브로커 장애에도 불구하고 연속적으로 안정적인 서비스를 제공하는데 카프카의 리플리케이션 동작을 위해
토픽 생성 시 필숫값으로 **replication factor**라는 옵션을 설정해야 한다.

우선 카프카의 기본 도구인 *kafka_topics.sh* 명령어를 이용해 토픽을 생성하고, 필수로 입력해야 하는 파티션 수는 **1**,
리플리케이션 팩터 수는 **3**으로 설정한다.

> 여기서 중요한 것은 실제로 리플리케이션 되는 것은 토픽이 아니라 토픽을 구성하는 각각의 파티션들이다.

이제 *kafka-console-product.sh* 명령어를 이용해 토픽에 메시지를 전송하면, 카프카는 해당 메시지를 토픽의 파티션(세그먼트 파일)에 저장하고
카프카 클러스터를 이루는 모든 브로커인 kafka01, kafka02, kafka03에 복제본을 전송한다.

이렇게 **replication factor**라는 옵션을 이용해 관리자가 지정한 수만큼의 리플리케이션을 가질 수 있기 때문에 N-1개 까지의 브로커 장애가 발생해도
메시지 손실 없이 안정적으로 메시지를 주고 받을 수 있다.

### 4.1.2 리더와 팔로워

카프카의 리플리케이션은 리더와 팔로워로 구성된다.

리더는 토픽의 파티션에 대한 모든 읽기와 쓰기 요청을 처리하고, 팔로워는 리더에 문제가 발생하거나 이슈가 있을 경우를 대비해 리더로부터 메시지를 복제하는 역할을 한다.

### 4.1.3 복제 유지와 커밋

리더와 팔로워는 ISR<sup>InSyncReplica</sup> 라는 논리적 그룹으로 묶여 있다.

따라서 ISR그룹에 속하지 못하는 팔로워는 새로운 리더의 자격을 가질 수 없게 된다.

팔로워가 어떤 이유로 리더로부터 리플리케이션하지 못하는 경우를 대비해 카프카는 리더와 팔로워 간의 메시지 전송을 통해 팔로워가 리더로부터 메시지를 복제하는지 확인하여
팔로워가 리플리케이션 동작을 잘하고 있는지 감시하게 된다.

만약 팔로워가 특정 주기의 시간만큼 복제 요청을 하지 않는다면 리더는 해당 팔로워에 문제가 발생했다고 판단 후 ISR그룹에서 제외시킨다.

ISR 내에서 모든 팔로워의 복제가 완료되면 리더는 내부적으로 **커밋**되었다는 표시를 하게 되는데 마지막 커밋 offset 위치를 하이워터마크<sup>high water mark</sup>라고 한다.

이렇게 모든 리플리케이션이 모두 메시지를 저장하게 되어 커밋된 메시지만 컨슈머가 읽어갈 수 있기 때문에 메시지의 일관성을 유지할 수 있게 된다.

### 4.1.4 리더와 팔로워의 단계별 리플리케이션 동작

카프카는 리더와 팔로워 간의 리플리케이션 동작을 처리할 때 서로의 통신을 최소화할 수 있도록 설계함으로써 리더의 부하를 줄였다.

1. ###### 리더는 메시지를 받아서 ISR그룹에 속한 팔로워에게 메시지를 전송한다.
    1. 하지만 팔로워들이 특정 오프셋에 대한 리플리케이션 성공여부를 알지 못한다.
    2. 전통적인 RabbitMQ 트랜잭션모드에서는 모든 Mirror<sup>팔로워</sup>와 ACK 통신을 하게되는데
    3. 카프카는 ACK통신을 제거함으로써 리플리케이션 동작의 성능을 더욱 높였다.
    4. M번 오프셋에 대한 리플리케이션 요청을 받은 리더는 팔로워들의 M-1번 오프셋에 대한 동작이 성공했음을 인지
    5. M번 오프셋에 대해 커밋 표시를 한 후 하이워터마크를 증가시킨다.
    6. 따라서 리더는 팔로워들이 보내는 요청 오프셋을 보고 어느 위치의 오프셋까지 동기화가 되었는지 확인할 수 있다.
2. ###### 팔로워는 리더로부터 메시지를 받아서 로컬 디스크에 저장한다.
    1. 리더의 응답을 받은 모든 팔로워는 M-1번 오프셋 메시지가 커밋되엇다는 사실을 인지하고 리더와 동일하게 커밋 표시를 한다.
    2. 그리고 M번 오프셋 메시지를 리플리케이션하게 되고 이 과정을 반복하여 동일한 파티션 내에서 리더와 팔로워 간 메시지의 일관성을 유지한다.
    3. ACK 통신을 제외했음에도 성능과 안정성을 보장할 수 있게 되는데
    4. 리더가 푸시<sup>push</sup>하는 방식이 아니라 팔로워들이 풀<sup>pull</sup>하는 방식으로 동작하기 때문에 리더의 부하를 줄여줄 수 있다.


### 4.1.5 리더에포크와 복구

리더에포크<sup>LeaderEpoch</sup>는 리더가 ISR그룹에 속한 팔로워들에게 메시지를 전송할 때마다 증가하는 값이다.

각 파티션들이 복구 동작을 할 때 메시지의 일관성을 유지하기 위한 용도로 사용되는데, 컨트롤러에 의해 관리되는 32비트의 숫자로 표현된다.

리더에포크가 없다면 복구 동작 시에 자신의 하이워터마크보다 높은 메시지를 즉시 삭제하기 때문에 메시지가 손실된다.

하지만 리더에포크를 사용한다면 하이워터마크보다 앞에 있는 메시지를 무조건 삭제하는 것이 아니다.

1. 팔로워는 복구 동작을 하면서 리더에게 리더에포크 요청을 보낸다.
2. 요청을 받은 리더는 리더에포크 응답으로 **`N번 오프셋의 K메시지까지`** 라고 팔로워에게 보낸다.
3. 팔로워는 자신의 하이워터마크보다 높은 1번 N번 오프셋의 K메시지를 삭제하지 않고 리더의 응답을 확인한 후 **`K+1`** 메시지까지 자신의 하이워터마크를 상향 조정한다
4. 이로써 메시지의 일관성을 유지할 수 있게 된다.

## 4.2 컨트롤러

카프카 클러스터 내에서는 컨트롤러라는 역할을 하는 브로커가 존재한다.
이 컨트롤러는 클러스터 내에서 리더를 선출하거나 파티션의 리플리케이션 동작을 관리하는 역할을 한다.

리더를 선출하기 위한 ISR 리스트 정보는 안전한 장소인 주키퍼에 저장되어 있고 컨트롤러는 브로커의 실패를 감지하면 즉시 ISR 리스트 중 하나를 새로운 파티션 리더로 선출한다.

파티션의 리더가 다운되면 해당 파티션으로 읽기나 쓰기가 불가능하기 때문에 설정되어있는 retry횟수만큼 재시도를 하게 되는데, 따라서 그 시간 내에 리더 선출 작업이 빠르게 이루어져야 한다.

이를 개선하고자 2018년 11월 릴리즈된 카프카 버전 1.1.0부터는 컨트롤러 선출을 위한 레이지 선출<sup>Lazy Controller</sup>이라는 기능이 추가되었다.


## 4.3 로그(로그 세그먼트)

카프카는 메시지를 저장할 때 로그 파일을 사용하는데, 이 로그 파일은 세그먼트 파일로 구성되어 있다.

로그 세그먼트에는 메시지의 내용뿐 아니라 메시지의 키, 밸류, 오프셋, 메시지크기 같은 정보가 함께 저장되며 이 파일은 브로커의 로컬 디스크에 보간된다.

하나의 로그 세그먼트 크기가 너무 커져버리면 파일을 관리하기 어렵기 때문에, 최대 크기는 1GB가 기본값으로 설정되어 있고
1GB보다 커지는 경우에는 기본적으로 롤링<sup>rolling</sup>전략을 적용한다.

하지만 이 로그 세그먼트 파일이 무한히 늘어날 경우를 대비해 파일 관리 계획을 수립해야 하는데 크게 로그 세그먼트 삭제와 컴팩션<sup>compactoin</sup>으로 구분할 수 있다.

### 4.3.1 로그 세그먼트 삭제

로그 세그먼트 삭제 옵션은 기본값이며 브로커 설정파일인 `server.properties`에서 `log.cleanup.policy`가 `delete`로 명시되어야 한다.

로그 세그먼트 삭제 작업은 기본값으로 5분 간격으로 파일을 체크하면서 삭제 작업을 수행하므로 명령어 실행 뒤 약 5분 후에 삭제 작업이 일어난다.

관리자는 토픽마다 보관 주기를 조정해서 얼마만큼의 기간 동안 보관할 것인지 설정할 수 있다. 토픽에 별도의 `retention.ms` 옵션을 설정하지 않으면 카프카의 `server.properteis`에
적용된 옵션값이 적용된다.
또한, `retention.bytes`라는 옵션을 이용해 지정된 크기를 기준으로도 로그 세그먼트 파일을 삭제할 수 있다.

### 4.3.2 로그 세그먼트 컴팩션

로그를 삭제하지 않고도 컴팩션하여 로그를 보관할 수 있다.

기본적으로 로컬 디스크에 저장되어 있는 세그먼트를 대상으로 실행되는데 현재 활성화된 세그먼트는 제외하고 나머지 세그먼트를 대상으로 컴팩션이 실행된다.

컴팩션하더라도 로컬 디스크에 로그를 무기한 보관한다면 용량은 감당할 수 없이 커져서 디스크가 저장할 수 있는 한계에 도달하기 때문에 카프카에서는
효율적으로 컴팩션한다.

메시지(record)의 키 값을 기준으로 마지막 데이터만 보관한다.

따라서 로그 컴팩션은 메시지의 키 값을 기준으로 과거 정보는 중요하지 않고 가장 마지막 값이 필요한 경우에 사용한다.
카프카에서 밸류는 필숫값이지만 키는 필숫값이 아니기 때문에 컴팩션을 사용하려면 키도 필수로 전송해야 한다.

컴팩션의 장점은 빠른 장애 복구인데 장애 복구 시에 전체 로그를 복구하지 않고 메시지의 키를 기준으로 최신의 상태만 복구하기 때문에 전체 로그 복구에 비해
복구 시간을 줄일 수 있다는 장점이 있다.

하지만 무분별하게 사용하기보다는 최종값만 필요한 워크로드에 적용하는 것이 바람직 하며 로그 컴팩션 작업이 실행되는 동안 브로커의 과도한
입출력 부하가 발생할 수 있으니 반드시 브로커의 리소스 모니터링을 병행하는 것을 권장한다.