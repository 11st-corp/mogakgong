# 카프카 기본 개념과 구조

---

## 카프카 구성 주요 요소

![Kafka Components](https://ibm-cloud-architecture.github.io/refarch-eda/technology/images/kafka-hl-view.png)

- Zookeeper
  - 카프카 메타데이터 관리 및 Health Check 담당
- Kafka / Kafka Cluster
  - 여러 Broker로 구성된 Kafka 클러스터
- Broker
  - Kafka 애플리케이션이 설치된 서버(노드)
- Producer
  - Kafka로 Message를 보내는 역할을 하는 클라이언트
- Consumer
  - Kafka에서 Message를 꺼내가는 역할을 하는 클라이언트
- Topic
  - Meesage Feed들을 Topic으로 구분하고, 각 Topic의 이름은 Kafka 내에서 Unique함
- Partition
  - 병렬 처리 및 고성능을 위해 하나의 Topic을 여러 개로 나눈 것
- Segment
  - Producer가 전송한 실제 Message가 Broker의 로컬 디스크에 저장되는 파일
- Message (Record)
  - Producer가 Kafka로 전송하거나 Consumer가 읽어가는 데이터 조각
  
### Replication

![Kafka Replication](https://docs.confluent.io/_images/replication.png)

각 메시지를 여러 개로 복제하여 Kafka 클러스터 내 Broker들에 분산시키는 동작. 이를 통해 하나의 Broker에 문제가 발생하더라도 Kafka가 안정성을 유지함.

```shell
$ bin/kafka-topics.sh --bootstrap-server [SERVERS] --create --topic [TOPIC] --partitions [PARTITIONS] --replication-factor [REPLICATION FACTORS]
```

`--replication-factor` 옵션으로 복제 수를 지정할 수 있으며, 안정성은 팩터 수에 비례한다. 다만 그만큼 Broker 리소스를 많이 사용하기 때문에 복제에 대한 Overhead를 줄여서 최대한 효율적으로 사용하는 것이 좋다. 일반적으로는 아래와 같이 사용하는 것을 권장하고 있다.

- 테스트 환경 : 1
- 운영 환경 : 로그성 메시지로서 약간의 유실을 허용하는 경우 2, 유실을 허용하지 않는 경우 3

### Partition

![Kafka Partitions](https://media.geeksforgeeks.org/wp-content/uploads/20220713194453/kafka1.png)

Topic이 한 번에 처리할 수 있는 한계를 높이기 위해 Topic 하나를 여러 개로 나눠 병렬 처리가 가능케 만든 것. 이렇게 되는 경우 분산 처리 또한 가능함.

#### 특징

- Partition의 번호는 0부터 시작한다.
- 마찬가지로 Topic을 생성할 때 Partition 수도 지정하는데, 한 번 지정 후 늘릴 수는 있지만 줄일 수는 없기 때문에 적절한 수를 정해야 함.
  - 메시지 처리량이나 Consumer Lag(Producer가 보낸 Message 수 - Consumer가 가져간 Message 수)를 모니터링하면서 조금씩 늘리는 것이 좋음.

### Segment

![Kafka Segments](https://www.conduktor.io/kafka/_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fo12xgu4mepom%2F1ZXlvPqblPzO4MZlqD0aQ1%2F5f9b4cece5ac705f92af4904e7fa9d92%2FAdv_Kafka_Topic_Internals_1.png&w=2048&q=75)

---

## Kafka 핵심 개념

### 분산 시스템

분산 시스템은 성능이 높다는 장점 외에도 하나의 서버(노드)에 문제가 발생하면 다른 서버가 처리하므로 장애 대응에도 탁월하며 부하가 높을 경우 시스템 확장에 용이하다는 특징이 있다. Kafka 또한 분산 시스템 구조이므로 더욱 높은 Message 처리를 위해 Broker를 늘림으로써 확장이 가능하다.

### 페이지 캐시

> 처리한 데이터를 RAM에 올려서 데이터 접근 발생시 Disk I/O 발생시키지 않고 처리하는 기법
> (+) Zero Copy : 일반적으로는 Disk에서 데이터를 읽고 RAM에 올려 네트워크 전송을 하지만, Zero Copy는 Disk에서 데이터를 읽음과 동시에 네트워크 전송을 함

- Producer가 Broker에 데이터를 로드할 때 즉시 Disk에 저장하는 대신 페이지 캐시에 저장한 후 일정 시간 뒤 Disk에 파일을 저장함
- Consumer가 데이터를 Broker에서 읽어갈 때 데이터를 페이지 캐시에 올려두어 동일 데이터를 다른 Consumer가 읽을 때 빠르게 읽을 수 있도록 함
- 일반적으로는 Disk I/O 시간이 많이 소요되기 때문에 Disk 기반이라 하면 느리게 보일 수 있으나 위와 같은 처리를 통해 빠른 속도를 유지

### 배치 전송 처리

데이터 전송은 높은 Cost를 요구하는데, 이러한 점을 고려했을 때 각 데이터를 개별 전송하는 것보다 배치로 전송하는 것이 더욱 효율적임을 알 수 있다. Kafka에서는 배치 전송 처리가 가능하여 효율적인 데이터 전송이 가능하다.

### 압축 전송

Message를 전송할 때 성능이 높은 압축 전송을 사용하는 것이 권장되는데 Kafk에서는 gzip, snappy, lz4, zstd 등을 지원한다. 압축만으로도 네트워크 대역폭과 회선 비용이 절약되어 높은 효과를 얻을 수 있다.

### Topic / Partition / Offset

Kafka에서의 데이터 저장은 Topic이라는 곳에 저장되며, 병렬 처리를 위해 Topic은 여러 Partition으로 나뉜다. 이와 같은 Partitioning을 통해 단 하나의 Topic이라도 높은 처리량 수행이 가능하다. 이 Partition의 메시지가 저장되는 위치는 Offset이라고 불리며 순차적으로 증가하는 64bit 정수로 구성된다. 각 Partition에서의 Offset은 고유한 숫자로, 이를 통해 Message 순서를 보장하고 Consumer에서는 마지막까지 읽은 위치를 알 수 있다.

### HA 보장

분산 시스템이기 때문에 특정 서버(노드)가 다운되어도 다른 서버(노드)가 장애발생 서버 역할을 대신하므로 안정적인 서비스가 가능. 이러한 고가용성 보장을 위하여 **Replication 기능**을 활용함. 이는 Topic 자체를 복제하는 것이 아닌 Topic의 Partition을 복제하는 것이다.

### Zookeeper 의존성

Zookeeper는 여러 대의 서버를 Ensemble (Cluster)로 구성하고, 살아 있는 노드 수가 과반수 이상 유지되면 지속적인 서비스가 가능한 구조. 따라서 반드시 홀수로 구성해야 한다.
znode를 이용해 Kafka 메타데이터가 Zookeeper에 기록되며, Zookeeper는 이러한 znode를 이용해 Broker의 노드 관리, Topic 관리, 컨트롤러 관리 등 매우 중요한 역할을 한다.

> 현재는 Zookeeper의 역할을 KRaft가 대체하고 있다. (v2.8 (Experimental), v3.3(Stable) ~)
> ![KRaft](https://images.ctfassets.net/gt6dp23g0g38/7gQZn9CnRAT60NeyYBYflL/b144fee6dad28ce97c3e91e6d09d1167/20230616-Diagram-KRaft.jpg)
> Zookeeper 의존성은 완전히 제거하면서 내부적으로 Raft 프로토콜을 사용하여 Leader 선출, 메타데이터 변경 사항의 로그 복제와 같은 작업을 수행함. 이는 Kafka Brokers 사이에서 일관된 상태를 유지하고, 클러스터의 메타데이터를 안정적으로 관리할 수 있도록 해줌.

---

## Kafka Producer / Consumer Code Example

![ProducerRecord](https://www.devtokki.com/data/data-platform/apache-kafka/kafka-basic-and-structure/producer.png)

[https://github.com/onlybooks/kafka2](https://github.com/onlybooks/kafka2)

### Producer 주요 Properties

|Option|Description|
|---|---|
|bootstrap.servers|Broker 정보로 여러 대 구성일 경우 comma separated|
|client.dns.lookup|하나의 Host에 여러 IP를 매핑하는 환경에서 클라이언트가 하나의 IP와 연결 못하는 경우 다른 IP로 시도하는 설정|
|acks|Producer가 Kafka Topic의 Leader측에 메시지를 전송한 후 요청을 완료하기를 결정하는 옵션으로 0(빠른 전송, 일부 Message 손실 가능성)/1(Leader의 Message 수신 확인, Follower 미확인)/all(-1, Follower 확인)로 표현.|
|buffer.memory|Producer가 Kafka 서버로 데이터를 보내기 위해 잠시 대기(배치 전송이나 Delay 등)할 수 있는 전체 메모리 byte|
|compression.type|Message 전송시 압축 방식|
|enable.idempotence|중복 전송 여부 (true, 이와 동시에 max.in.flight.requests.per.connection는 5 이하, retries는 0 이상, acks는 all로 설정해야 함)|
|max.in.flight.requests.per.connection|하나의 Connection에서 Producer가 최대한 ACK 없이 전송할 수 있는 요청 수로 메시지 순서가 중요할 경우 1로 설정|
|retries|일시적 오류일 때 전송에 실패한 데이터의 재전송 횟수|
|batch.size|배치 전송 크기|
|linger.ms|배치 형태의 Message를 보내기 전 추가적인 Message를 위해 기다리는 시간을 조정하고, 배치 크기에 도달하지 못한 상황에서 linger.ms 제한 시간에 도달했을 때 Message 전송|
|transactional.id|정확히 한 번 전송을 위해 사용하는 옵션으로 동일한 Transaction ID에 한해 정확히 한 번 전송을 보장함. 이 때 enable.idempotence를 true로 설정해야 함|

### Consumer 주요 Properties

|Option|Description|
|---|---|
|bootstrap.servers|Broker 정보로 여러 대 구성일 경우 comma separated|
|fetch.min.bytes|한 번에 가져올 수 있는 최소 데이터 크기. 지정한 크기보다 작은 경우 요청에 응답하지 않고 데이터가 누적될 때까지 대기|
|group.id|Consumer가 속한 Consumer 그룹 식별자|
|heartbeat.interval.ms|Consumer의 Heartbeat Time 설정. session.timeout.ms보다 작아야 하며 일반적으로는 이 값의 1/3로 설정.|
|max.partition.fetch.bytes|Partition당 가져올 수 있는 최대 크기|
|session.timeout.ms|이 시간을 이용해 Consumer가 종료되었는지 판단, Consumer는 주기적으로 Heartbeat를 보내야 하며 시간 내 Heartbeat가 오지 않을 경우 종료된 것으로 간주하여 Consumer Group에서 제외하고 Rebalancing 진행|
|enable.auto.commit|백그라운드에서 주기적으로 Offset Commit할 지 여부|
|fetch.max.bytes|한 번의 가져오기 요청으로 가져올 수 있는 최대 크기|
|group.instance.id|Consumer의 고유 식별자. 만약 설정하는 경우 static 멤버로 간주되어 불필요한 Rebalancing을 하지 않음.|
|isolation.level|Transaction Consumer에서 사용되는 옵션으로 read_uncommitted는 기본값으로 모든 메시지를 읽으며 read_committed는 Transaction이 완료된 Message만 읽음|
|max.poll.records|한 번의 poll() 요청으로 가져오는 최대 Message 수|
|partition.assignment.strategy|Partition 할당 전략으로 기본값은 range|
|fetch.max.wait.ms|fetch.min.bytes에 의해 설정된 데이터보다 적은 경우 요청에 대한 응답을 기다리는 최대 시간|
