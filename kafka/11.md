# 11. 카프카 커넥트

카프카 커넥트란?

- 아파치 카프카의 오픈소스 프로젝트 중 하나
- 외부 시스템 (ex. 데이터베이스)과 카프카를 손쉽게 연결하기 위한 프레임워크
  - 대용량 데이터를 카프카 안팎으로 이동
  - 코드를 작성하지 않고도 간단히 사용 가능

카프카 커넥트의 장점

- 데이터 중심의 파이프라인
- 유연성과 화장성
  - 테스트 및 일회성 작업을 위한 standalone 모드로 실행 가능. 대규모 운영 환경을 위한 분산 모드로도 실행 가능
- 재사용성과 기능 확장
  - 이미 만들어진 기존 커넥터들 활용가능. 운영환경에서의 요구사항에 따른 빠른 확장 가능 → 운영 오버헤드 절감
- 장애 및 복구
  - 분산 모드 사용시 워커 노드의 장애 상황에도 유영한 대응이 가능하여 고가용성이 보장됨.

# 카프카 커넥트의 핵심 개념

- 카프카 클러스터 양쪽 옆에 배치 (소스 옆 - 소스 커넥트, 싱크 옆 - 싱크 커넥트)

<img width="643" alt="image" src="https://github.com/user-attachments/assets/3d0bc2bf-1ee7-408e-afa6-22a1c2e1a907">


- 소스 커넥트
  - 굳이 비교하자면 소스/카프카 사이에 프로듀서 역할
- 싱크 커넥트
  - 굳이 비교하자면 카프카/싱크 사이에 컨슈머 역할
- 커넥트 내부 - 분산모드 vs 단독 모드
  - 분산 모드 : 여러 대의 워커(커넥터와 태스크를 실행)가 커넥트 내부에 존재 (장애 대응에 좋음)
  - 단독 모드 : 한 대의 워커
- 커넥터
  - 데이터를 어디에서 어디로 복사해야 하는지 작업을 정의&관리 (직접 데이터 복사 X)
  - ex. JDBC 소스 커넥터 : RDBMS → 카프카 전송, HDFS 싱크 커넥터 : 카프카 적재 데이트 → HDFS로 적재

# 커넥트의 내부 동작

[https://docs.confluent.io/platform/current/connect/devguide.html](https://docs.confluent.io/platform/current/connect/devguide.html)

![image](https://github.com/user-attachments/assets/e278fe3f-bfac-4516-9e1c-4ac419818eda)


1. 데이터들을 레코드 순서에 맞춰 파티셔닝
  - 파티션에는 오프셋 포함 - 장애나 실패가 발생해도 지정된 위치에서 데이터 이동 가능
2. stream에서 나눈 파티션들을 2개의 Task에 할당
  - Task : 실제 데이터를 이동하는 동작 처리
3. 각 태스크는 데이터를 Kafka의 토픽으로 전송

## 카프카 커넥트의 컨버터

소스에서 카프카로 전송할 때 직렬화(Serialization)와 카프카에서 싱크로 전송할 때의 역직렬화-(deserialization)를 담당

- 카프카 커넥트에서 컨버트를 통해 카프카로 전송하고, 카프카 내부에서 데이터 포맷을 표준화된 상태로 처리가 가능하기 때문에 불필요하게 컨버팅 코드를 작성하지 않아도 됨.

<img width="694" alt="image" src="https://github.com/user-attachments/assets/d5b7b9d4-bf0f-4d72-89cc-b9d3242e35e0">

## 카프카 커넥트의 REST API

커넥트의 상태를 확인하기 위한 REST API 제공

- 커넥트를 재시작하지 않고도 동적으로 커넥터 설정과 옵션 변경 가능

| API 옵션 | 설명 |
| --- | --- |
| GET / | 커넥트의 버전과 클러스터 ID 확인 |
| GET /connectors | 커넥터 리스트 확인 |
| GET /connectors/커넥터 이름 | 커넥터 이름의 상세 내용 확인 |
| GET /connectors/7-E/ 0/E/config | 커넥터 이름의 config 정보 확인 |
| GET /connectors/74E/ 0/E/status | 커넥터 이름의 상태 확인 |
| PUT / connectors/714E/ OlE/config | 커넥터 config 설정 |
| PUT /connectors/7/4/ 0/E/pause | 커넥터의 일시 중지 |
| PUT /connectors/7/4/ 0/E/resume | 커넥터의 다시 시작 |
| DELETE/connectors/커넥터 이름 | 커넥터의 삭제 |
| GET /connectors/7/4/ 0/E/tasks | 커넥터의 태스크 정보 확인 |
| GET /connectors/커넥터 이름/tasks/태스크 ID/
status | 커넥터에서 특정 태스크의 상태 확인 |
| POST /connectors/커넥터 이름/tasks/태스크 ID/
restart | 커넥터에서 특정 태스크 재시작 |

# 커넥터 기반의 미러 메이커 2.0

미러 메이커 

- 카프카와 카프카 간 리플리케이션을 하기 위한 도구
- 카프카 간 리플리케이션 하는 경우? 장애 복구, 온프레미스 데이터를 클라우드로 마이그레이션, 데이터 분석 용도

기존 미러 메이커 1.0 

- 간단한 컨슈머, 프로듀서가 내장된 도구
- 다양한 옵션이 필요한 엔터프라이즈 환경에 맞는 추가 기능은 제공X

미러 메이커 2.0

- 1.0에서 추가/개선한 기능 포함
- 카프카 커넥트 프레임워크 기반으로 간단한 설정만으로도 손쉬운 확장이 가능함
- 기능
  - 원격 토픽과 에일리어스(alias) 가능
  - 카프카 클러스터 통합 (다중 클러스터로부터 미러링된 토픽들을 다운스트림 컨슈머가 통합)
  - 무한 루프 방지
  - 토픽 설정 동기화 (소스 토픽 모니터링 & 토픽 설정 변경사항 → 원격 대상 토픽으로 전파)
  - 내부 토픽을 활용한 안전한 저장소로 사용
  - 카프카 커넥트 지원 (카프카 커넥트 기반만으로도 미러 메이커 2.0 동작 가능 - like spirng boot 에 내장된 tomcat)
- 실행 방법
  - 전용 미러 메이커 클러스터
  - 분산 커넥트 클러스터에서 미러 메이커 커넥터 이용
  - 독립형인 커넥트 워커
  - 스크립트 사용 (레거시 방식)
